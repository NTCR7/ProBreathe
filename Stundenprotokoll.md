# ProBreathe - Stundenprotokoll
**Ein Projekt von Nele und Tim Ratzka**

<img src="images/ProBreathe-banner.png" width="1200" alt="ProBreathe-Banner">

## Timeline üìÖ
|     16.01.23    |     14.02.23    | 20.03.-26.03.23 | 27.03.-02.04.23 | 03.04.-09.04.23 | 24.04.-30.04.23 | 01.05.-07.05.23 | 08.05.-14.05.23 | 15.05.-21.05.23 | 22.05.-28.05.23 | 29.05.-04.06.23 | 05.06.-11.06.23 | 12.06.-18.06.23 | 19.06.-25.06.23 |
| ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- | ------------- |

## 16.01.23
Diese Stunde wurde von einer Ideensammlung und engagierten Diskussionen gepr√§gt. Obwohl das Stattenfinden des Unterrichts unklar war, begannen wir bereits zuhause neue Projektideen zu entwickeln. Uns war schnell klar; Die Weiterentwicklung unseres ProPLant Projekts mit dem Arduino war nicht genug. Wir wollen uns dieses Semester v√∂llig von der physical computing Welt l√∂sen und den Fokus auf ein tiefgreifenderes Programm legen.  "Was f√ºr ein Projekt wollen wir dieses Jahr machen?" stellte sich als ziemlich komplexe Frage heraus, da wir beide unterschiedliche Ans√§tze w√§hlen wollten. Allerdings waren wir uns √ºber eine Sache sofort im Klaren; Es sollte sich um ein Pythonprojekt handeln. Schon seit Beginn des Informatikunterrichts interessieren wir uns aufgrund unz√§hliger Anwendungsbereiche und unglaublichen Projekten f√ºr die Programmiersprache Python. Zudem stie√üen wir auf die folgende Statistik, was unsere Annahme best√§tigte. Python ist eine so essentielle Programmiersprache, die wir unbedingt beherrschen wollten. Auch wenn wir uns dabei von Grund auf in die Programmiersprache einarbeiten m√ºssen.

<details>
<summary>ausschlaggebende Statistiküìä</summary>
  <img src="images/most-searched-programming-languages-2023.png" width="700" alt="Statistik der meistgesuchten Programmiersprachen in 2023">
</details>

Wir haben uns noch nicht endg√ºltig f√ºr ein konkretes Projekt entscheiden k√∂nnen, aber wir wollten es auf jeden Fall mit der Medizin in Verbindung bringen. Wir haben beide eine Leidenschaft f√ºr dieses Thema und wissen, dass uns ein solches Projekt sehr viel Spa√ü machen w√ºrde.

## 14.02.23
Nun wollten wir unser Projekt in seinem Fundament festlegen, sodass wir uns mit dem tats√§chlichen Programmieren und Lernen besch√§ftigen k√∂nnen.
Weitere Inspiration f√ºr ein Python-Projekt versuchten wir heute durch Recherchen zu bekommen, obwohl unser Fokus eigentlich schon feststand: Von der Idee und den M√∂glichkeiten von AI schon immer fasziniert, wollten wir uns unbedingt in diese Richtung orientieren. Vor dem Unterricht hatten wir schon viele Artikel √ºber k√ºnstliche Intelligenz und deep learning gelesen. Wir waren entschlossen, auch ein solches Programm zu entwickeln! Bei unseren Recherchen stie√üen wir auf Projekte wie die Vorhersage f√ºr Aktienkurse, movie recommendations oder auch das Erkennen handschriftlicher Zeichen. Am meisten faszinierte uns allerdings die Image Classification mithilfe eines CNNs. Nat√ºrlich fanden wir auch Projekte zum Klassiker der Iris Classification. Allerdings sollte unser Anwendungsbereich auf alle F√§lle in der Medizin liegen und wir erkundeten verschiedenen Ans√§tze wie die Einsch√§tzung des Herzens. Au√üerdem stellten wir fest, dass sich die Plattform kaggle f√ºr ML besonders gut eignen w√ºrde, da viele Projkete hier auf die bereits bestehenden Datens√§tze zugriffen. Dies brachte uns auch auf die Spur der Klassifizierung von R√∂ntgenaufnahmen der Lunge als gesund oder von einer Lungenentz√ºndung betroffen. Der vorhandene Datensatz festigte unsere √úberzeugung; wir wollten ein solches Projekt hinsichtlich der Lungenentz√ºndung in Angriff nehmen. Herr Buhl konnte unsere Projektidee best√§tigen. Die restliche Zeit wurde damit verbracht, sich mit den Begriffen Neuronales Netz, Deep Learning, Machine Learning und Convolutional Neuronal Network auseinanderzusetzen.

## 20.03.-26.03.23
So wie wir uns ein ehrgeiziges Projekt ausgesucht hatten, ging es jetzt daran die Komponenten Python und das CNN v√∂llig zu durchdringen. Durch umfassende Internetrechereche identifizierten wir die wichtigsten Komponenten unseres Projektes. Dabei spielten neben dem CNN und seiner Architektur auch die Datenvorbereitung und die Anwendung eine gro√üe Rolle. Dazu ordneten wir unsere Gedanken folgenderma√üen:
<p align="center">
 <img src="images/CNN-1.-Gedanken.png" width="700" alt="strukturierte Gedanken zu CNN"> 
<p/>
Au√üerdem haben wir uns √ºber zahlreiche Python-Tutorials weitergebildet. Zudem erstellten wir unser erstes Notebook auf kaggle. Dabei lernten wir mit den Einstellungen der Plattform umzugehen. Kaggle ist speziell auf das Arbeiten an deep learning Projekten mit riesigen Datens√§tzen ausgelegt, was sich als gro√üer Vorteil f√ºr uns erweist. Allerdings ist das Einarbeiten zwingend erforderlich gewesen, hinsichtlich der Einbindung des Datensatzes, oder wie das Notebook gespeichert werden kann. Wir beginnen also, uns mit der Plattform vertraut zu machen <a href="https://www.kaggle.com/">kaggle</a>. Der bereits vorhandene <a href="https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia">Datensatz</a> l√∂st ein gro√ües Problem, welches bei der Arbeit mit Python besteht: Der enorme Zeitaufwand einen Datensatz in aufwendiger repetitiver Eigenarbeit zu erstellen. Einen enormen Datensatz von echten Lungen-R√∂ntgenbildern zu finden, erwies sich vorher als unm√∂glich. Der Datensatz von kaggle ist bereits in drei Ordner aufgeteilt "Test", "Train" und "Val". Diese Ordner besitzen jeweils die Unterkategorien "Pneumonia" und "Normal", auf welche die 5.863 R√∂ntgenbilder von Lungen als JPEGs aufgeteilt sind. Au√üerdem sind In- und Output bereits komfortabel integriert und die Plattform erm√∂glicht ein gemeinsames Arbeiten von beiden Projektmitgliedern von unterschiedlichen Ger√§ten aus. Schlie√ülich wurde der Datensatz in den Input eingebunden. Au√üerdem schauten wir uns ein Beispiel einer Lungenentz√ºndungsvorhersage an. 

## 27.03.-02.04.23
Wir beginnen erstmal mit dem Importieren der wichtigsten Bibliotheken, die f√ºr das Projekt ben√∂tigt wurden. Dabei kam es erst zu Fehlermeldungen, da einige Pythonpakete vorher √ºber `!pip install` installiert werden m√ºssen, bevor die Bibliotheken importiert werden k√∂nnen. Hier ist auch zu beachten, dass bei kaggle speziell das `! ` ben√∂tigt wird, was so bei Python normalerweise nicht der Fall ist. Ebenfalls widmen wir uns dem ersten Aspekt der Datenvorbereitung. Das Definieren der `get_data ` Funktion lief reibungslos ab. Allerdings kommt es beim Aufrufen der Funktion f√ºr die Test-, Trainings- und Validierungsdaten zu einer Fehlermeldung. N√§mlich kann kaggle die angegebenen Pfade zu den Ordnern nicht finden. Der erste L√∂sungsansatz bestand darin, die Leseberechtigung mit folgendem Code zu √ºberpr√ºfen:
```c 

import os

directory_path = '../kaggle/input/chest-xray-pneumonia/chest_xray/test'

if os.access(directory_path, os.R_OK):
    print("Der Code hat Leseberechtigungen f√ºr das Verzeichnis.")
else:
    print("Der Code hat keine Leseberechtigungen f√ºr das Verzeichnis.")
```
Allerdings lag hier gar nicht das Problem. Nach Recherche bei kaggle lag es an den Notebook Options. Hier musste das Internet wie folgt aktiviert werden:

<img src="images/kaggle-internet-explanation.JPEG" width="500" alt="kaggle-internet-explanation">

So lernten wir allerdings auch vertieft weiter den Aufbau und Umgang mit der Plattform. Au√üerdem nahmen wir erfolgreich die Aufteilung in Feature und Label-Arrays vor. Um einen √úberblick √ºber den Datensatz zu erhalten, visualisierten wir au√üerdem die Anzahl der F√§lle als Balkendiagramm und zwei Beispiele:
<p align="center">
 <img src="images/output-images.png" width="1200" alt="Balkendiagramm und zwei Beispiele"> 
<p/>
Bei der Anpassung der Daten kam es zu einem Hindernis. Wir waren verwirrt, dass nur das `x_train/test/val` mit `reshape` ver√§ndert wird. Hier mussten wir uns nochmal einen √úberblick verschaffen; So besteht die Modellarchitektur in der letzten Schicht aus einem einzigen Neuron mit der Sigmoid-Aktivierungsfunktion. Diese erwartet, dass die Label-Arrays eindimensional sind. Somit ist folgender Code √ºberfl√ºssig:

 <img src="images/useless-code.png" width="600" alt="√úberfl√ºssiger Code"> 

## 03.04.-09.04.23
Beide Gruppenmitglieder waren in der Zeit vom 03.04. - 05.04. krankheitsbedingt verhindert. Eine Weiterarbeit am Projekt war in dieser Zeit nicht m√∂glich. Au√üerdem wurde dadurch die Teilnahme am Fachtag verhindert. Auch die restlichen Tage waren aufgrund der schulischen Beanspruchung, des Nachholbedarfs und der Genesung weniger produktiv. 

## 24.04.-30.04.23
Wir schlossen nun die Datenvorbereitung in den letzten Z√ºgen ab und widmeten uns nun der Fertigstellung unserer Modellarchitektur. Die letzte Schicht hatten wir direkt festgelegt, nachdem wir in diesem Zug daf√ºr die Anpassung der y-Arrays nicht ben√∂tigt hatten. Wir setzten uns nun konkreter mit der Schreibweise in Python f√ºr die Schichten des Modells auseinander, da wir die einzelnen Komponenten bereits kennengelernt hatten, aber nicht wussten nach welchem Schema diese im Code eingebunden werden. Die Erstellung der Modellarchitektur erfolgte ansonsten sehr zielstrebig, da der Aufbau der Schichten f√ºr jede weitere Schicht gleichbleibt. Wir setzten die Anzahl der `Conv2D` Schichten vorerst auf 5, da √§hnliche Projekte auch diesen Ansatz w√§hlten. Zudem informierten wir uns noch √ºber Optimierungsfunktionen und andere Regularisierung und legten uns da auch fest. Zum Beispiel haben wir den callback `learning rate reducation` in seinen Parametern wie dem Faktor, um die die Lernrate reduziert wird, festgelegt.

## 01.05.-07.05.23
Nachdem nun die Modellarchitektur feststand, widmeten wir uns dem Training des Modells und experimentierten mit der Epochenanzahl und Batchgr√∂√üe. Um dies zu beurteilen, schrieben wir den Code, um die Leistung des Modells zu beurteilen, also die `accuracy `. Daf√ºr griffen wir auf die `model.evaluate ` Funktion zur√ºck. G√§ngig erschienen 10 Epochen und wir tasteten uns an h√∂here Genauigkeiten heran. Dabei ist auch zu beachten, dass eine kleinere Zahl bei `batch_size =` zu einer l√§ngeren Rechoperation f√ºhrt. So ist die Batch-Gr√∂√üe 20 daf√ºr verantwortlich, dass 261 Batches durchlaufen werden.

<img src="images/batches_epochs.png" width="750" alt="Code Preview"> 

## 08.05.-14.05.23
In dieser Woche setzen wir uns nun mit der Anwendung unseres Projektes auf unbekannte Bilder auseinander. Daf√ºr sahen wir uns bei `gradio` die verschiedenen Interfaces an und versuchten den Code f√ºr jenes, bei welchem man ein Bild einpflegt und ein Label erh√§lt, umzusetzen. Den Grundstein hatten wir gelegt, nun musste allerdings die Klassifizierung des Modells noch festgelegt werden. Daf√ºr muss der Schwellenwert zwischen 0 und 1 liegen, da die letzte Schicht diese bin√§re Klassifikation ausgibt. Auf der Hand lag der Wert 0.5, da er die Mitte darstellt. Allerdings √ºberlegten wir den Wert weiter runterzusetzen, damit das CNN vorsichtiger ist und eher die Krankheit diagnostiziert. Die Falschdiagnose als gesund w√§re ein schwerwiegender Fehler. Jedoch entschieden wir uns dagegen, da dies die Ergebnisse zu sehr verf√§lscht.

## 15.05.-21.05.23
Mittlerweile sind wir soweit, dass wir ein Video als "proof of concept" am Fachtag vorstellen konnten. Leider konnte nur Tim an dem Fachtag teilnehmen, da Nele aus gesundheitlichen Gr√ºnden nicht teilnehmen konnte. W√§hrend des Tages hat Tim daher haupts√§chlich an der GitHub Projektseite gearbeitet. Au√üerdem wurde von Tim versucht, die Genauigkeit des Modells zu verbessern. Dies war jedoch nicht m√∂glich. Durch einen mehrmaligen Raumwechsel musste der Trainingsprozess immer wieder neu gestartet werden. Das lag nat√ºrlich auch daran, dass die Anzahl der Epochen in diesem Experiment sehr hoch war und der gesamte Code f√ºr einen Durchlauf 1,5 Stunden in Anspruch nahm. Derzeit muss das Programm bei jedem Durchlauf f√ºr 1:10h neu trainiert werden, was nat√ºrlich sehr zeitaufwendig und benutzerunfreundlich ist. Deshalb soll der Trainingsfortschritt gespeichert und beim n√§chsten Mal wieder abgerufen werden. Bis jetzt waren wir nicht in der Lage, den Code oder das Modell zu speichern und Tim hat versucht, eine L√∂sung f√ºr dieses Problem zu finden und die L√∂sung schien in Keras zu liegen. Es wurde √ºber Checkpoints und das Speichern des gesamten Codes gesprochen. Das Ziel war, dass ein Benutzer nur das Interface √∂ffnen muss und dann direkt interagieren kann, um das Modell zu testen. 

## 22.05.-28.05.23
Aufgrund von MUNOL war Nele erneut die geamte Woche nicht anwesend. Tim war aufgrund eines hohen schulischen Aufkommens und der prkatischen F√ºhrerscheinpr√ºfung ebenfalls verhindert.

## 29.05.-04.06.23
Wir konnten Herr Buhl den Code und die einzelnen Abteile ausf√ºhrlich zeigen und erl√§utern. (Wir einigten uns au√üerdem darauf, dass wir die Paramter als Einflussfaktoren analysieren.) Nun begann erneut auch der zeitraubendste Teil, n√§mlich das empirische Schrauben an den Parameter und das anschlie√üende Durchlaufen der Epochen um die Leistung zu evaluieren.

## 05.06.-11.06.23
Wir wagten uns an die Ver√§nderung unserer Modellarchitektur, wobei wir mit unterschiedlichen Schichten experimentierten. Um Over Fitting zu vermeiden, verringerten wir die Schichtenanzahl der `Conv2D ` Schichten auf 3. Letztendlich ergaben sich 5 trotzdem als am effizientesten.

## 12.06.-18.06.23
Die Frage, wie man den Fortschritt des Modells speichern kann, haben wir am Fachtag weiter untersucht. Es wurde auch getestet, ob es m√∂glich ist, das Modell auf der Grundlage des gespeicherten Verlaufs neu zu trainieren, um die Genauigkeit immer wieder zu verbessern. Dies war jedoch nicht so einfach zu bewerkstelligen, und wir mussten die Idee nach einer Menge Arbeit wieder fallen lassen. Schlie√ülich kamen wir unserem Ziel n√§her. Wir mussten nur noch die Teile des Codes ausf√ºhren, die das Training und die Schnittstelle betrafen. Das Durchlaufen des vorherigen Teils war nicht mehr notwendig, da wir einfach das letzte Modell laden und direkt mit dem Training beginnen konnten. Dabei wurden Trainingsfortschritt und Genauigkeit √ºberschrieben.

## 19.06.-25.06.23
Zuletzt erh√∂hten wir den Umfang unseres Projektes enorm, da wir es uns zur Aufgabe gemacht hatten, den Einfluss der Parameter genau zu untersuchen. Dabei drehten wir einmal an Stellschrauben der data augmentation, wobei beispielsweise die zuf√§llige Drehung des Bildes um 30 Grad die Effizienz verringert, obwohl das Gegenteil der Fall sein soll. Dar√ºber hinaus informierten wir uns √ºber die Grid Search Funktion, die es erm√∂glicht, die beste Kombination der Hypermparamter zu ermitteln. Das Programmieren dieser Funktion nahm neue Ausma√üe an, zumal neue Bibliotheken wie sciKeras ben√∂tigt wurden und die Funktion auf verschiedene Parameter beschr√§nkt ist. Daf√ºr schrieben wir auch Code um diese auszugeben.
Zuvor hatte der Code nicht funktioniert, weil er unsere Anforderungen nicht umsetzen konnte. Da die Funktion jede Kombinationsm√∂glichkeit der ausgew√§hlten Parameter durchl√§uft, beschr√§nkten wir uns auf verschiedene Epochen und Batches.  Dies f√ºhrte uns zu unserem besten Ergebnis des Modells und wir legten die schlussendlichen Parameter fest. Der Aufwand war erheblich, da wir verschiedenen Versuche abbrechen mussten. Beispielsweise Durchlaufen die Funktion beim ersten Versuch, die Parameter √ºber 11 Stunden und war trotzdem nicht fertig.
